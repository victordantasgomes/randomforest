{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnostico</th>\n",
       "      <th>exame_1</th>\n",
       "      <th>exame_2</th>\n",
       "      <th>exame_3</th>\n",
       "      <th>exame_4</th>\n",
       "      <th>exame_5</th>\n",
       "      <th>exame_6</th>\n",
       "      <th>exame_7</th>\n",
       "      <th>exame_8</th>\n",
       "      <th>...</th>\n",
       "      <th>exame_24</th>\n",
       "      <th>exame_25</th>\n",
       "      <th>exame_26</th>\n",
       "      <th>exame_27</th>\n",
       "      <th>exame_28</th>\n",
       "      <th>exame_29</th>\n",
       "      <th>exame_30</th>\n",
       "      <th>exame_31</th>\n",
       "      <th>exame_32</th>\n",
       "      <th>exame_33</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>103.78</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>...</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.786</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>103.78</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>...</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.786</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>103.78</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>...</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.786</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>103.78</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>...</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.786</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>103.78</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>...</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.786</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>0.854454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>843786</td>\n",
       "      <td>M</td>\n",
       "      <td>12.45</td>\n",
       "      <td>15.70</td>\n",
       "      <td>82.57</td>\n",
       "      <td>103.78</td>\n",
       "      <td>477.1</td>\n",
       "      <td>0.12780</td>\n",
       "      <td>0.17000</td>\n",
       "      <td>0.15780</td>\n",
       "      <td>...</td>\n",
       "      <td>103.40</td>\n",
       "      <td>741.6</td>\n",
       "      <td>0.1791</td>\n",
       "      <td>0.5249</td>\n",
       "      <td>0.5355</td>\n",
       "      <td>0.786</td>\n",
       "      <td>0.1741</td>\n",
       "      <td>0.3985</td>\n",
       "      <td>0.12440</td>\n",
       "      <td>0.804347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>844359</td>\n",
       "      <td>M</td>\n",
       "      <td>18.25</td>\n",
       "      <td>19.98</td>\n",
       "      <td>119.60</td>\n",
       "      <td>103.78</td>\n",
       "      <td>1040.0</td>\n",
       "      <td>0.09463</td>\n",
       "      <td>0.10900</td>\n",
       "      <td>0.11270</td>\n",
       "      <td>...</td>\n",
       "      <td>153.20</td>\n",
       "      <td>1606.0</td>\n",
       "      <td>0.1442</td>\n",
       "      <td>0.2576</td>\n",
       "      <td>0.3784</td>\n",
       "      <td>0.786</td>\n",
       "      <td>0.1932</td>\n",
       "      <td>0.3063</td>\n",
       "      <td>0.08368</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>84458202</td>\n",
       "      <td>M</td>\n",
       "      <td>13.71</td>\n",
       "      <td>20.83</td>\n",
       "      <td>90.20</td>\n",
       "      <td>103.78</td>\n",
       "      <td>577.9</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>0.16450</td>\n",
       "      <td>0.09366</td>\n",
       "      <td>...</td>\n",
       "      <td>110.60</td>\n",
       "      <td>897.0</td>\n",
       "      <td>0.1654</td>\n",
       "      <td>0.3682</td>\n",
       "      <td>0.2678</td>\n",
       "      <td>0.786</td>\n",
       "      <td>0.1556</td>\n",
       "      <td>0.3196</td>\n",
       "      <td>0.11510</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>844981</td>\n",
       "      <td>M</td>\n",
       "      <td>13.00</td>\n",
       "      <td>21.82</td>\n",
       "      <td>87.50</td>\n",
       "      <td>103.78</td>\n",
       "      <td>519.8</td>\n",
       "      <td>0.12730</td>\n",
       "      <td>0.19320</td>\n",
       "      <td>0.18590</td>\n",
       "      <td>...</td>\n",
       "      <td>106.20</td>\n",
       "      <td>739.3</td>\n",
       "      <td>0.1703</td>\n",
       "      <td>0.5401</td>\n",
       "      <td>0.5390</td>\n",
       "      <td>0.786</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.4378</td>\n",
       "      <td>0.10720</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>84501001</td>\n",
       "      <td>M</td>\n",
       "      <td>12.46</td>\n",
       "      <td>24.04</td>\n",
       "      <td>83.97</td>\n",
       "      <td>103.78</td>\n",
       "      <td>475.9</td>\n",
       "      <td>0.11860</td>\n",
       "      <td>0.23960</td>\n",
       "      <td>0.22730</td>\n",
       "      <td>...</td>\n",
       "      <td>97.65</td>\n",
       "      <td>711.4</td>\n",
       "      <td>0.1853</td>\n",
       "      <td>1.0580</td>\n",
       "      <td>1.1050</td>\n",
       "      <td>0.786</td>\n",
       "      <td>0.2210</td>\n",
       "      <td>0.4366</td>\n",
       "      <td>0.20750</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id diagnostico  exame_1  exame_2  exame_3  exame_4  exame_5  exame_6  \\\n",
       "0    842302           M    17.99    10.38   122.80   103.78   1001.0  0.11840   \n",
       "1    842517           M    20.57    17.77   132.90   103.78   1326.0  0.08474   \n",
       "2  84300903           M    19.69    21.25   130.00   103.78   1203.0  0.10960   \n",
       "3  84348301           M    11.42    20.38    77.58   103.78    386.1  0.14250   \n",
       "4  84358402           M    20.29    14.34   135.10   103.78   1297.0  0.10030   \n",
       "5    843786           M    12.45    15.70    82.57   103.78    477.1  0.12780   \n",
       "6    844359           M    18.25    19.98   119.60   103.78   1040.0  0.09463   \n",
       "7  84458202           M    13.71    20.83    90.20   103.78    577.9  0.11890   \n",
       "8    844981           M    13.00    21.82    87.50   103.78    519.8  0.12730   \n",
       "9  84501001           M    12.46    24.04    83.97   103.78    475.9  0.11860   \n",
       "\n",
       "   exame_7  exame_8  ...  exame_24  exame_25  exame_26  exame_27  exame_28  \\\n",
       "0  0.27760  0.30010  ...    184.60    2019.0    0.1622    0.6656    0.7119   \n",
       "1  0.07864  0.08690  ...    158.80    1956.0    0.1238    0.1866    0.2416   \n",
       "2  0.15990  0.19740  ...    152.50    1709.0    0.1444    0.4245    0.4504   \n",
       "3  0.28390  0.24140  ...     98.87     567.7    0.2098    0.8663    0.6869   \n",
       "4  0.13280  0.19800  ...    152.20    1575.0    0.1374    0.2050    0.4000   \n",
       "5  0.17000  0.15780  ...    103.40     741.6    0.1791    0.5249    0.5355   \n",
       "6  0.10900  0.11270  ...    153.20    1606.0    0.1442    0.2576    0.3784   \n",
       "7  0.16450  0.09366  ...    110.60     897.0    0.1654    0.3682    0.2678   \n",
       "8  0.19320  0.18590  ...    106.20     739.3    0.1703    0.5401    0.5390   \n",
       "9  0.23960  0.22730  ...     97.65     711.4    0.1853    1.0580    1.1050   \n",
       "\n",
       "   exame_29  exame_30  exame_31  exame_32  exame_33  \n",
       "0     0.786    0.2654    0.4601   0.11890       NaN  \n",
       "1     0.786    0.1860    0.2750   0.08902       NaN  \n",
       "2     0.786    0.2430    0.3613   0.08758       NaN  \n",
       "3     0.786    0.2575    0.6638   0.17300       NaN  \n",
       "4     0.786    0.1625    0.2364   0.07678  0.854454  \n",
       "5     0.786    0.1741    0.3985   0.12440  0.804347  \n",
       "6     0.786    0.1932    0.3063   0.08368       NaN  \n",
       "7     0.786    0.1556    0.3196   0.11510       NaN  \n",
       "8     0.786    0.2060    0.4378   0.10720       NaN  \n",
       "9     0.786    0.2210    0.4366   0.20750       NaN  \n",
       "\n",
       "[10 rows x 35 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Experimento simples de uso do Random Forest sem redução de dimensões e comparando com um baseline usando DummyClassifier\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Leitura do dataset\n",
    "resultados_exames = pd.read_csv(\".\\data-set\\exames.csv\")\n",
    "\n",
    "# Exibição dos 10 primeiros registros\n",
    "resultados_exames.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569, 35)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exibindo a dimensionalidade do dataframe\n",
    "resultados_exames.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>exame_1</th>\n",
       "      <th>exame_2</th>\n",
       "      <th>exame_3</th>\n",
       "      <th>exame_4</th>\n",
       "      <th>exame_5</th>\n",
       "      <th>exame_6</th>\n",
       "      <th>exame_7</th>\n",
       "      <th>exame_8</th>\n",
       "      <th>exame_9</th>\n",
       "      <th>exame_10</th>\n",
       "      <th>...</th>\n",
       "      <th>exame_23</th>\n",
       "      <th>exame_24</th>\n",
       "      <th>exame_25</th>\n",
       "      <th>exame_26</th>\n",
       "      <th>exame_27</th>\n",
       "      <th>exame_28</th>\n",
       "      <th>exame_29</th>\n",
       "      <th>exame_30</th>\n",
       "      <th>exame_31</th>\n",
       "      <th>exame_32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>103.78</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.786</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>103.78</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.786</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>103.78</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.786</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>103.78</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.786</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>103.78</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.786</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>12.45</td>\n",
       "      <td>15.70</td>\n",
       "      <td>82.57</td>\n",
       "      <td>103.78</td>\n",
       "      <td>477.1</td>\n",
       "      <td>0.12780</td>\n",
       "      <td>0.17000</td>\n",
       "      <td>0.15780</td>\n",
       "      <td>0.08089</td>\n",
       "      <td>0.2087</td>\n",
       "      <td>...</td>\n",
       "      <td>23.75</td>\n",
       "      <td>103.40</td>\n",
       "      <td>741.6</td>\n",
       "      <td>0.1791</td>\n",
       "      <td>0.5249</td>\n",
       "      <td>0.5355</td>\n",
       "      <td>0.786</td>\n",
       "      <td>0.1741</td>\n",
       "      <td>0.3985</td>\n",
       "      <td>0.12440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>18.25</td>\n",
       "      <td>19.98</td>\n",
       "      <td>119.60</td>\n",
       "      <td>103.78</td>\n",
       "      <td>1040.0</td>\n",
       "      <td>0.09463</td>\n",
       "      <td>0.10900</td>\n",
       "      <td>0.11270</td>\n",
       "      <td>0.07400</td>\n",
       "      <td>0.1794</td>\n",
       "      <td>...</td>\n",
       "      <td>27.66</td>\n",
       "      <td>153.20</td>\n",
       "      <td>1606.0</td>\n",
       "      <td>0.1442</td>\n",
       "      <td>0.2576</td>\n",
       "      <td>0.3784</td>\n",
       "      <td>0.786</td>\n",
       "      <td>0.1932</td>\n",
       "      <td>0.3063</td>\n",
       "      <td>0.08368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>13.71</td>\n",
       "      <td>20.83</td>\n",
       "      <td>90.20</td>\n",
       "      <td>103.78</td>\n",
       "      <td>577.9</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>0.16450</td>\n",
       "      <td>0.09366</td>\n",
       "      <td>0.05985</td>\n",
       "      <td>0.2196</td>\n",
       "      <td>...</td>\n",
       "      <td>28.14</td>\n",
       "      <td>110.60</td>\n",
       "      <td>897.0</td>\n",
       "      <td>0.1654</td>\n",
       "      <td>0.3682</td>\n",
       "      <td>0.2678</td>\n",
       "      <td>0.786</td>\n",
       "      <td>0.1556</td>\n",
       "      <td>0.3196</td>\n",
       "      <td>0.11510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>13.00</td>\n",
       "      <td>21.82</td>\n",
       "      <td>87.50</td>\n",
       "      <td>103.78</td>\n",
       "      <td>519.8</td>\n",
       "      <td>0.12730</td>\n",
       "      <td>0.19320</td>\n",
       "      <td>0.18590</td>\n",
       "      <td>0.09353</td>\n",
       "      <td>0.2350</td>\n",
       "      <td>...</td>\n",
       "      <td>30.73</td>\n",
       "      <td>106.20</td>\n",
       "      <td>739.3</td>\n",
       "      <td>0.1703</td>\n",
       "      <td>0.5401</td>\n",
       "      <td>0.5390</td>\n",
       "      <td>0.786</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.4378</td>\n",
       "      <td>0.10720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>12.46</td>\n",
       "      <td>24.04</td>\n",
       "      <td>83.97</td>\n",
       "      <td>103.78</td>\n",
       "      <td>475.9</td>\n",
       "      <td>0.11860</td>\n",
       "      <td>0.23960</td>\n",
       "      <td>0.22730</td>\n",
       "      <td>0.08543</td>\n",
       "      <td>0.2030</td>\n",
       "      <td>...</td>\n",
       "      <td>40.68</td>\n",
       "      <td>97.65</td>\n",
       "      <td>711.4</td>\n",
       "      <td>0.1853</td>\n",
       "      <td>1.0580</td>\n",
       "      <td>1.1050</td>\n",
       "      <td>0.786</td>\n",
       "      <td>0.2210</td>\n",
       "      <td>0.4366</td>\n",
       "      <td>0.20750</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   exame_1  exame_2  exame_3  exame_4  exame_5  exame_6  exame_7  exame_8  \\\n",
       "0    17.99    10.38   122.80   103.78   1001.0  0.11840  0.27760  0.30010   \n",
       "1    20.57    17.77   132.90   103.78   1326.0  0.08474  0.07864  0.08690   \n",
       "2    19.69    21.25   130.00   103.78   1203.0  0.10960  0.15990  0.19740   \n",
       "3    11.42    20.38    77.58   103.78    386.1  0.14250  0.28390  0.24140   \n",
       "4    20.29    14.34   135.10   103.78   1297.0  0.10030  0.13280  0.19800   \n",
       "5    12.45    15.70    82.57   103.78    477.1  0.12780  0.17000  0.15780   \n",
       "6    18.25    19.98   119.60   103.78   1040.0  0.09463  0.10900  0.11270   \n",
       "7    13.71    20.83    90.20   103.78    577.9  0.11890  0.16450  0.09366   \n",
       "8    13.00    21.82    87.50   103.78    519.8  0.12730  0.19320  0.18590   \n",
       "9    12.46    24.04    83.97   103.78    475.9  0.11860  0.23960  0.22730   \n",
       "\n",
       "   exame_9  exame_10  ...  exame_23  exame_24  exame_25  exame_26  exame_27  \\\n",
       "0  0.14710    0.2419  ...     17.33    184.60    2019.0    0.1622    0.6656   \n",
       "1  0.07017    0.1812  ...     23.41    158.80    1956.0    0.1238    0.1866   \n",
       "2  0.12790    0.2069  ...     25.53    152.50    1709.0    0.1444    0.4245   \n",
       "3  0.10520    0.2597  ...     26.50     98.87     567.7    0.2098    0.8663   \n",
       "4  0.10430    0.1809  ...     16.67    152.20    1575.0    0.1374    0.2050   \n",
       "5  0.08089    0.2087  ...     23.75    103.40     741.6    0.1791    0.5249   \n",
       "6  0.07400    0.1794  ...     27.66    153.20    1606.0    0.1442    0.2576   \n",
       "7  0.05985    0.2196  ...     28.14    110.60     897.0    0.1654    0.3682   \n",
       "8  0.09353    0.2350  ...     30.73    106.20     739.3    0.1703    0.5401   \n",
       "9  0.08543    0.2030  ...     40.68     97.65     711.4    0.1853    1.0580   \n",
       "\n",
       "   exame_28  exame_29  exame_30  exame_31  exame_32  \n",
       "0    0.7119     0.786    0.2654    0.4601   0.11890  \n",
       "1    0.2416     0.786    0.1860    0.2750   0.08902  \n",
       "2    0.4504     0.786    0.2430    0.3613   0.08758  \n",
       "3    0.6869     0.786    0.2575    0.6638   0.17300  \n",
       "4    0.4000     0.786    0.1625    0.2364   0.07678  \n",
       "5    0.5355     0.786    0.1741    0.3985   0.12440  \n",
       "6    0.3784     0.786    0.1932    0.3063   0.08368  \n",
       "7    0.2678     0.786    0.1556    0.3196   0.11510  \n",
       "8    0.5390     0.786    0.2060    0.4378   0.10720  \n",
       "9    1.1050     0.786    0.2210    0.4366   0.20750  \n",
       "\n",
       "[10 rows x 32 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importação das bibliotecas para splits dos datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from numpy import random\n",
    "\n",
    "# Criando o SEED para controlar a aleatoriedade\n",
    "SEED = 123143\n",
    "random.seed(SEED)\n",
    "\n",
    "# Separando as colunas de id, diagnóstico e exame_33 do dataset\n",
    "# id está sendo excluída por não agregar valor ao processo de treinamento\n",
    "# Á coluna diagnóstico está sendo escluída por ser o target da minha classificação\n",
    "# A coluna exame_33 está sendo escluída por só conter valores vazios\n",
    "valores_exames = resultados_exames.drop(columns=['id', 'diagnostico','exame_33'])\n",
    "valores_exames.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treino x: (398, 32)  | Teste x: (171, 32)  | Treino y: (398,)  | Teste y: (171,)\n"
     ]
    }
   ],
   "source": [
    "# Capturando agora só as colunas de id e diagnóstico\n",
    "diagnostico = resultados_exames.diagnostico\n",
    "#diagnostico.head(10)\n",
    "\n",
    "# Segregando os dados em bases de treino e teste e setando o tamanho da base de teste para 30% (o padrão da base de teste é de 25%)\n",
    "treino_x, teste_x, treino_y, teste_y = train_test_split(valores_exames, diagnostico, test_size=0.3)\n",
    "\n",
    "# treino_x.head()\n",
    "# teste_x.head()\n",
    "# treino_y.head()\n",
    "# teste_y.head()\n",
    "print(\"Treino x: \" + str(treino_x.shape), \" | Teste x: \" + str(teste_x.shape), \" | Treino y: \" + str(treino_y.shape), \" | Teste y: \" + str(teste_y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultado da classificação: 92.40%\n"
     ]
    }
   ],
   "source": [
    "# Importação do Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Instanciando o Random Forest setando o parâmetro do número de árvores de decisão que serão geradas para 100 (por padrão são geradas 10 árvores) \n",
    "classificador = RandomForestClassifier(n_estimators = 100)\n",
    "\n",
    "# Treinando o modelo com base nos datasets de treino\n",
    "classificador.fit(treino_x, treino_y)\n",
    "\n",
    "# Como o Random Forest não aceita valores vazios como entrada, precisamos tratar os valores vazios\n",
    "\n",
    "# Imprimindo o atributo score do resultado da classificação\n",
    "print(\"Resultado da classificação: %.2f%%\" %(classificador.score(teste_x,teste_y)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultado da classificação boba: 66.67%\n",
      "Resultado da classificação com Random Forest: 92.4%\n",
      "Diferença de : 25.73%\n"
     ]
    }
   ],
   "source": [
    "# Precisamos ter um base line para saber se o resultado da nossa classificação é bom ou não. Para isso, iremos criar um novo modelo de classificação utilizando o dummy classifier.\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "# Criando o fator de aloiretariedade para o novo classificador\n",
    "SEED = 123143\n",
    "random.seed(SEED)\n",
    "\n",
    "# Instanciando o novo classificador com a estratégia most_frequent: a predição sempre retorna o rótulo de classe mais frequente no argumento y observado passado para fit.\n",
    "# O método predict_proba retorna o vetor codificado one-hot correspondente. Basicamente ele chuta o valor mais comum para y.\n",
    "classificador_bobo = DummyClassifier(strategy= \"most_frequent\")\n",
    "\n",
    "# Treinando o novo modelo \n",
    "classificador_bobo.fit(treino_x, treino_y)\n",
    "\n",
    "resultado_classificador_bobo = round((classificador_bobo.score(teste_x, teste_y)*100),2)\n",
    "resultado_classificador_rf = round((classificador.score(teste_x, teste_y)*100),2)\n",
    "# Imprimindo o atributo score do novo resultado da classificação\n",
    "print(\"Resultado da classificação boba: \" + str(resultado_classificador_bobo) + \"%\")\n",
    "print(\"Resultado da classificação com Random Forest: \" + str(resultado_classificador_rf)+ \"%\")\n",
    "\n",
    "# Comparando nosso resultado utilizando o Random Forest com o classificador bobo, podemos deduzir que o resultado do RF é muito bom e que nossa classificação está correta.\n",
    "print(\"Diferença de : \" + str(round((resultado_classificador_rf - resultado_classificador_bobo),2))+ \"%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "ad7b75af0c7805cb18e35c82102a8f454a04b3bfd116e571cb4f5885c211fa58"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
